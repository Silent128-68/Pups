import re
import sys
from typing import List, Tuple, Dict, NamedTuple

# Req 1: –û–±–Ω–æ–≤–ª—è–µ–º Lexeme, –¥–æ–±–∞–≤–ª—è—è line –∏ col
class Lexeme(NamedTuple):
    value: str
    type: str
    category: str
    line: int
    col: int

# –ö–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞
KEYWORDS = {
    'do': 'DO',
    'until': 'UNTIL',
    'loop': 'LOOP',
    'input': 'INPUT',
    'output': 'OUTPUT',
    'and': 'LOGICAL_OP',
    'or': 'LOGICAL_OP',
    'not': 'LOGICAL_NOT',
}

# Req 3: –û–±–Ω–æ–≤–ª—è–µ–º TOKEN_SPECS
# –ú—ã –æ–±—ä–µ–¥–∏–Ω—è–µ–º ID –∏ NUMBER, —á—Ç–æ–±—ã –ø—Ä–∞–≤–∏–ª—å–Ω–æ –ª–æ–≤–∏—Ç—å –æ—à–∏–±–∫–∏ —Ç–∏–ø–∞ '1output'
TOKEN_SPECS = [
    # –≠—Ç–∞ –≥—Ä—É–ø–ø–∞ –î–û–õ–ñ–ù–ê –±—ã—Ç—å –ø–µ—Ä–≤–æ–π.
    # 1. –í–∞–ª–∏–¥–Ω—ã–π ID: [A-Za-z][A-Za-z0-9_]*
    # 2. –¢–æ–∫–µ–Ω, –Ω–∞—á–∏–Ω–∞—é—â–∏–π—Å—è —Å —Ü–∏—Ñ—Ä—ã: \d+[A-Za-z0-9_]* (–º–æ–∂–µ—Ç –±—ã—Ç—å –≤–∞–ª–∏–¥–Ω—ã–º '123' –∏–ª–∏ –Ω–µ–≤–∞–ª–∏–¥–Ω—ã–º '123x')
    ('ID_OR_NUM', r'[A-Za-z][A-Za-z0-9_]*|\d+[A-Za-z0-9_]*'),
    
    # –û–ø–µ—Ä–∞—Ç–æ—Ä—ã (–ø–æ—Ä—è–¥–æ–∫ –≤–∞–∂–µ–Ω, –æ—Ç –¥–ª–∏–Ω–Ω—ã—Ö –∫ –∫–æ—Ä–æ—Ç–∫–∏–º)
    ('OP',        r'<<|<=|>=|==|<>|[<>=+\-*/;()=]'),
    
    # –ü—Ä–æ–ø—É—Å–∫ –ø—Ä–æ–±–µ–ª–æ–≤
    ('SKIP',      r'[ \t\r]+'), # –£–±—Ä–∞–ª–∏ \n, —Ç–∞–∫ –∫–∞–∫ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –ø–æ—Å—Ç—Ä–æ—á–Ω–æ
    
    # –û—à–∏–±–∫–∞ (–ª—é–±–æ–π –¥—Ä—É–≥–æ–π –æ–¥–∏–Ω–æ—á–Ω—ã–π —Å–∏–º–≤–æ–ª)
    ('MISMATCH',  r'.'),
]

token_regex = re.compile('|'.join('(?P<%s>%s)' % pair for pair in TOKEN_SPECS))

def lex(line_text: str, line_num: int, id_table: Dict[str, int], const_table: Dict[str, int]) -> List[Lexeme]:
    """
    –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –æ–¥–Ω—É —Å—Ç—Ä–æ–∫—É —Ç–µ–∫—Å—Ç–∞.
    –ó–∞–ø–æ–ª–Ω—è–µ—Ç id_table –∏ const_table.
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ø–∏—Å–æ–∫ –ª–µ–∫—Å–µ–º –ò–õ–ò –≤—ã–∑—ã–≤–∞–µ—Ç ValueError –ø—Ä–∏ –æ—à–∏–±–∫–µ.
    """
    lexemes: List[Lexeme] = []
    
    # –ü–æ–ª—É—á–∞–µ–º —Ç–µ–∫—É—â–∏–µ –º–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–µ –∏–Ω–¥–µ–∫—Å—ã –¥–ª—è —Ç–∞–±–ª–∏—Ü
    next_id = len(id_table) + 1
    next_const = len(const_table) + 1

    # –ò—Ç–µ—Ä–∏—Ä—É–µ–º—Å—è –ø–æ –≤—Å–µ–º —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è–º –≤ —Å—Ç—Ä–æ–∫–µ
    for mo in token_regex.finditer(line_text):
        kind = mo.lastgroup
        val = mo.group(0)
        col = mo.start() + 1 # +1 –¥–ª—è –Ω—É–º–µ—Ä–∞—Ü–∏–∏ —Å—Ç–æ–ª–±—Ü–æ–≤ —Å 1

        if kind == 'ID_OR_NUM':
            # Req 3: –õ–æ–≥–∏–∫–∞ –¥–ª—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ ID, NUMBER –∏–ª–∏ –û–®–ò–ë–ö–ò
            if val[0].isdigit():
                if val.isdigit():
                    # --- –í–ê–õ–ò–î–ù–ê–Ø –ö–û–ù–°–¢–ê–ù–¢–ê ---
                    lexemes.append(Lexeme(val, 'CONSTANT', 'constant', line_num, col))
                    if val not in const_table:
                        const_table[val] = next_const
                        next_const += 1
                else:
                    # --- –ù–ï–í–ê–õ–ò–î–ù–´–ô –¢–û–ö–ï–ù (–Ω–∞–ø—Ä. '1output') ---
                    # Req 2: –í—ã–∑—ã–≤–∞–µ–º –æ—à–∏–±–∫—É –∏ –æ—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º—Å—è
                    raise ValueError(f"–°—Ç—Ä–æ–∫–∞ {line_num}, –ø–æ–∑. {col}: –ù–µ–¥–æ–ø—É—Å—Ç–∏–º—ã–π —Ç–æ–∫–µ–Ω (–∏–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ç–æ—Ä –Ω–µ –º–æ–∂–µ—Ç –Ω–∞—á–∏–Ω–∞—Ç—å—Å—è —Å —Ü–∏—Ñ—Ä—ã): '{val}'")
            
            elif val[0].isalpha():
                # --- –í–ê–õ–ò–î–ù–´–ô ID –∏–ª–∏ KEYWORD ---
                low = val.lower()
                if low in KEYWORDS:
                    lexemes.append(Lexeme(val, KEYWORDS[low], 'keyword', line_num, col))
                else:
                    lexemes.append(Lexeme(val, 'IDENTIFIER', 'identifier', line_num, col))
                    if low not in id_table:
                        id_table[low] = next_id
                        next_id += 1
        
        elif kind == 'OP':
            # –õ–æ–≥–∏–∫–∞ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ –æ–ø–µ—Ä–∞—Ç–æ—Ä–æ–≤ (–æ—Å—Ç–∞–ª–∞—Å—å –ø—Ä–µ–∂–Ω–µ–π)
            op_type, op_cat = 'UNKNOWN_OP', 'operation' # –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é
            if val == ';':
                op_type, op_cat = 'SEMICOLON', 'symbol'
            elif val in ('+', '-', '*', '/'):
                op_type, op_cat = 'ARITHMETIC', 'operation'
            elif val in ('<=', '>=', '==', '<>', '<', '>'):
                op_type, op_cat = 'COMPARISON', 'operation'
            elif val == '=':
                op_type, op_cat = 'ASSIGNMENT', 'operation'
            elif val == '<<':
                op_type, op_cat = 'IO_OP', 'operation'
            elif val in ('(', ')'):
                op_type, op_cat = 'PAREN', 'symbol'
            
            lexemes.append(Lexeme(val, op_type, op_cat, line_num, col))
            
        elif kind == 'SKIP':
            continue # –ü—Ä–æ—Å—Ç–æ –ø—Ä–æ–ø—É—Å–∫–∞–µ–º –ø—Ä–æ–±–µ–ª—ã

        elif kind == 'MISMATCH':
            # Req 2: –í—ã–∑—ã–≤–∞–µ–º –æ—à–∏–±–∫—É –∏ –æ—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º—Å—è
            raise ValueError(f"–°—Ç—Ä–æ–∫–∞ {line_num}, –ø–æ–∑. {col}: –ù–µ–¥–æ–ø—É—Å—Ç–∏–º—ã–π —Å–∏–º–≤–æ–ª: {val!r}")

    return lexemes

# --- –§—É–Ω–∫—Ü–∏–∏ –¥–ª—è –≤—ã–≤–æ–¥–∞ —Ç–∞–±–ª–∏—Ü ---

# Req 1: –û–±–Ω–æ–≤–ª—è–µ–º print_table –¥–ª—è –≤—ã–≤–æ–¥–∞ –ø–æ–∑–∏—Ü–∏–∏
def print_table(title: str, headers: list, rows: list):
    widths = [len(h) for h in headers]
    for row in rows:
        for i, val in enumerate(row):
            widths[i] = max(widths[i], len(str(val)))

    total_width = sum(widths) + len(widths) * 3 + 1
    print(f"\n{title}")
    print("‚îÄ" * total_width)
    header_line = "‚îÇ " + " ‚îÇ ".join(f"{h:<{w}}" for h, w in zip(headers, widths)) + " ‚îÇ"
    print(header_line)
    print("‚îú" + "‚îº".join("‚îÄ" * (w + 2) for w in widths) + "‚î§")

    for row in rows:
        print("‚îÇ " + " ‚îÇ ".join(f"{str(v):<{w}}" for v, w in zip(row, widths)) + " ‚îÇ")

    print("‚îÄ" * total_width)

def main():
    try:
        with open("FL_1lab_input.txt", "r", encoding="utf-8") as f:
            text = f.read()
    except FileNotFoundError:
        print("‚ùå –§–∞–π–ª FL_1lab_input.txt –Ω–µ –Ω–∞–π–¥–µ–Ω.")
        return

    print("\nüìò –õ–µ–∫—Å–∏—á–µ—Å–∫–∏–π –∞–Ω–∞–ª–∏–∑ –ø—Ä–æ–≥—Ä–∞–º–º—ã")
    print("–ò—Å—Ö–æ–¥–Ω—ã–π –∫–æ–¥:\n" + "‚îÄ" * 50)
    print(text)
    print("‚îÄ" * 50)

    all_lexemes: List[Lexeme] = []
    id_table: Dict[str, int] = {}
    const_table: Dict[str, int] = {}

    # Req 2: –û–±–æ—Ä–∞—á–∏–≤–∞–µ–º –∞–Ω–∞–ª–∏–∑ –≤ try...except
    try:
        # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –ø–æ—Å—Ç—Ä–æ—á–Ω–æ
        lines = text.splitlines()
        for line_num, line_text in enumerate(lines, 1):
            # –ü–µ—Ä–µ–¥–∞–µ–º —Ç–∞–±–ª–∏—Ü—ã, —á—Ç–æ–±—ã –æ–Ω–∏ –Ω–∞–ø–æ–ª–Ω—è–ª–∏—Å—å
            lexemes_on_line = lex(line_text, line_num, id_table, const_table)
            all_lexemes.extend(lexemes_on_line)
            
    except ValueError as e:
        # –õ–æ–≤–∏–º –ø–µ—Ä–≤—É—é –∂–µ –ª–µ–∫—Å–∏—á–µ—Å–∫—É—é –æ—à–∏–±–∫—É –∏ –ø—Ä–µ—Ä—ã–≤–∞–µ–º –∞–Ω–∞–ª–∏–∑
        print(f"‚ùå –û–®–ò–ë–ö–ê –õ–ï–ö–°–ò–ß–ï–°–ö–û–ì–û –ê–ù–ê–õ–ò–ó–ê:")
        print(e)
        print("\n–ê–Ω–∞–ª–∏–∑ –ø—Ä–µ—Ä–≤–∞–Ω.")
        sys.exit(1) # –í—ã—Ö–æ–¥ —Å –∫–æ–¥–æ–º –æ—à–∏–±–∫–∏

    # --- –ï—Å–ª–∏ –æ—à–∏–±–æ–∫ –Ω–µ –±—ã–ª–æ, –ø–µ—á–∞—Ç–∞–µ–º —Ç–∞–±–ª–∏—Ü—ã ---

    # –¢–∞–±–ª–∏—Ü–∞ –ª–µ–∫—Å–µ–º
    # Req 1: –î–æ–±–∞–≤–ª—è–µ–º "–ü–æ–∑–∏—Ü–∏—è" –≤ –≤—ã–≤–æ–¥
    rows = []
    for i, lx in enumerate(all_lexemes):
        pos = f"–°—Ç—Ä–æ–∫–∞ {lx.line}, –ø–æ–∑. {lx.col}"
        rows.append((i + 1, lx.value, lx.type, lx.category, pos))
        
    print_table("–¢–∞–±–ª–∏—Ü–∞ –ª–µ–∫—Å–µ–º", ["‚Ññ", "–õ–µ–∫—Å–µ–º–∞", "–¢–∏–ø", "–ö–∞—Ç–µ–≥–æ—Ä–∏—è", "–ü–æ–∑–∏—Ü–∏—è"], rows)

    # –¢–∞–±–ª–∏—Ü–∞ –∏–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ç–æ—Ä–æ–≤
    rows_id = [(i, name) for name, i in sorted(id_table.items(), key=lambda kv: kv[1])]
    print_table("–¢–∞–±–ª–∏—Ü–∞ –∏–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ç–æ—Ä–æ–≤", ["‚Ññ", "–ò–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ç–æ—Ä"], rows_id)

    # –¢–∞–±–ª–∏—Ü–∞ –∫–æ–Ω—Å—Ç–∞–Ω—Ç
    rows_c = [(i, val) for val, i in sorted(const_table.items(), key=lambda kv: kv[1])]
    print_table("–¢–∞–±–ª–∏—Ü–∞ –∫–æ–Ω—Å—Ç–∞–Ω—Ç", ["‚Ññ", "–ö–æ–Ω—Å—Ç–∞–Ω—Ç–∞"], rows_c)

    print("\n‚úÖ –ê–Ω–∞–ª–∏–∑ —É—Å–ø–µ—à–Ω–æ –∑–∞–≤–µ—Ä—à—ë–Ω!")

if __name__ == "__main__":
    main()
